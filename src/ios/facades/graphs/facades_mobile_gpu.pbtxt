# "ios/prebuilt/facades/graphs/facades_mobile_gpu.pbtext"
# https://github.com/61315/mediapipe-prebuilt/tree/master/src/ios/facades

# MediaPipe graph that runs pix2pix variant with TensorFlow Lite on GPU.

# Input image. (ImageFrame)
input_stream: "IMAGE_GPU:input_video"

# Output image with rendered results. (ImageFrame)
output_stream: "IMAGE_GPU:output_video"

node {
  calculator: "FlowLimiterCalculator"
  input_stream: "input_video"
  input_stream: "FINISHED:output_video"
  input_stream_info: {
    tag_index: "FINISHED"
    back_edge: true
  }
  output_stream: "throttled_input_video"
}

# Calculate size of the image.
node {
  calculator: "ImagePropertiesCalculator"
  input_stream: "IMAGE_GPU:throttled_input_video"
  output_stream: "SIZE:image_size"
}

node {
  calculator: "ImageCroppingCalculator"
  input_stream: "IMAGE_GPU:throttled_input_video"
  output_stream: "IMAGE_GPU:cropped_input_video"
  node_options: {
    [type.googleapis.com/mediapipe.ImageCroppingCalculatorOptions] {
      width: 256
      height: 256
      norm_center_x: 0.5
      norm_center_y: 0.5
    }
  }
}

# Converts the transformed input image on GPU into an image tensor stored in
# TfLiteTensor. The zero_center option is set to true to normalize the
# pixel values to [-1.f, 1.f] as opposed to [0.f, 1.f]. With the
# max_num_channels option set to 4, all 4 RGBA channels are contained in the
# image tensor.
node {
  calculator: "TfLiteConverterCalculator"
  input_stream: "IMAGE_GPU:cropped_input_video"
  output_stream: "TENSORS_GPU:image_tensor"
  node_options: {
    [type.googleapis.com/mediapipe.TfLiteConverterCalculatorOptions] {
      zero_center: true
      max_num_channels: 4
    }
  }
}

# Runs a TensorFlow Lite model on GPU that takes an image tensor and outputs a
# tensor representing the bitmap, which has the same width and height
# as the input image tensor.
node {
  calculator: "TfLiteInferenceCalculator"
  input_stream: "TENSORS_GPU:image_tensor"
  output_stream: "TENSORS:bitmap_tensor"
  node_options: {
    [type.googleapis.com/mediapipe.TfLiteInferenceCalculatorOptions] {
      model_path: "mediapipe/examples/ios/prebuilt/facades/models/facades_mobile_quant.tflite"
      delegate { gpu {} }
    }
  }
}

# Decodes the bitmap tensor generated by the TensorFlow Lite model into a
# image of values in [0, 255], stored in a CPU buffer.
node {
  calculator: "TfLiteTensorsToImageFrameCalculator"
  input_stream: "TENSORS:bitmap_tensor"
  output_stream: "IMAGE:translated_image_cpu"
  node_options: {
    [type.googleapis.com/mediapipe.TfLiteTensorsToImageFrameCalculatorOptions] {
      tensor_width: 256
      tensor_height: 256
      tensor_channels: 3
      scale_factor: 255.0
    }
  }
}

node {
  calculator: "ImageFrameToGpuBufferCalculator"
  input_stream: "translated_image_cpu"
  output_stream: "translated_image"
}

node: {
  calculator: "ImageTransformationCalculator"
  input_stream: "IMAGE_GPU:translated_image"
  input_stream: "OUTPUT_DIMENSIONS:image_size"
  output_stream: "IMAGE_GPU:output_video"
  node_options: {
    [type.googleapis.com/mediapipe.ImageTransformationCalculatorOptions] {
      scale_mode: FIT
    }
  }
}
