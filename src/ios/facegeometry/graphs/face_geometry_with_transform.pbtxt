# MediaPipe graph that extract transformation data from detected faces
# on a live video stream.
# Used in the examples in mediapipe/examples/ios/prebuilt/facegeometry.

# GPU image. (ImageFrame)
input_stream: "input_video"

# GPU image. (ImageFrame)
output_stream: "output_video"

output_stream: "MULTI_FACE_GEOMETRY:multi_face_geometry"

# Throttles the images flowing downstream for flow control. It passes through
# the very first incoming image unaltered, and waits for downstream nodes
# (calculators and subgraphs) in the graph to finish their tasks before it
# passes through another image. All images that come in while waiting are
# dropped, limiting the number of in-flight images in most part of the graph to
# 1. This prevents the downstream nodes from queuing up incoming images and data
# excessively, which leads to increased latency and memory usage, unwanted in
# real-time mobile applications. It also eliminates unnecessarily computation,
# e.g., the output produced by a node may get dropped downstream if the
# subsequent nodes are still busy processing previous inputs.
node {
    calculator: "FlowLimiterCalculator"
    input_stream: "input_video"
    input_stream: "FINISHED:multi_face_geometry"
    input_stream_info: {
        tag_index: "FINISHED"
        back_edge: true
    }
    output_stream: "throttled_input_video"
}

# Calculate size of the image.
node {
    calculator: "ImagePropertiesCalculator"
    input_stream: "IMAGE_GPU:throttled_input_video"
    output_stream: "SIZE:input_image_size"
}

# Defines how many faces to detect. Iris tracking currently only handles one
# face (left and right eye), and therefore this should always be set to 1.
node {
    calculator: "ConstantSidePacketCalculator"
    output_side_packet: "PACKET:0:num_faces"
    node_options: {
        [type.googleapis.com/mediapipe.ConstantSidePacketCalculatorOptions]: {
            packet { int_value: 1 }
        }
    }
}

# Detects faces and corresponding landmarks.
node {
    calculator: "FaceLandmarkFrontGpu"
    input_stream: "IMAGE:throttled_input_video"
    input_side_packet: "NUM_FACES:num_faces"
    output_stream: "LANDMARKS:multi_face_landmarks"
    output_stream: "ROIS_FROM_LANDMARKS:face_rects_from_landmarks"
    output_stream: "DETECTIONS:face_detections"
    output_stream: "ROIS_FROM_DETECTIONS:face_rects_from_detections"
}

# Generates an environment that describes the current virtual scene.
node {
    calculator: "FaceGeometryEnvGeneratorCalculator"
    output_side_packet: "ENVIRONMENT:environment"
    node_options: {
        [type.googleapis.com/mediapipe.FaceGeometryEnvGeneratorCalculatorOptions] {
            environment: {
                origin_point_location: TOP_LEFT_CORNER
                perspective_camera: {
                    vertical_fov_degrees: 63.0  # 63 degrees
                    near: 1.0  # 1cm
                    far: 10000.0  # 100m
                }
            }
        }
    }
}

# Extracts a single set of face landmarks associated with the most prominent
# face detected from a collection.
node {
  calculator: "SplitNormalizedLandmarkListVectorCalculator"
  input_stream: "multi_face_landmarks"
  output_stream: "face_landmarks"
  node_options: {
    [type.googleapis.com/mediapipe.SplitVectorCalculatorOptions] {
      ranges: { begin: 0 end: 1 }
      element_only: true
    }
  }
}

# Applies smoothing to the single set of face landmarks.
node {
  calculator: "FaceLandmarksSmoothing"
  input_stream: "NORM_LANDMARKS:face_landmarks"
  input_stream: "IMAGE_SIZE:input_image_size"
  output_stream: "NORM_FILTERED_LANDMARKS:smoothed_face_landmarks"
}

# Puts the single set of smoothed landmarks back into a collection to simplify
# passing the result into the `FaceGeometryFromLandmarks` subgraph.
node {
  calculator: "ConcatenateNormalizedLandmarkListVectorCalculator"
  input_stream: "smoothed_face_landmarks"
  output_stream: "multi_smoothed_face_landmarks"
}

# Subgraph that renders face-landmark annotation onto the input image.
node {
    calculator: "FaceRendererGpu"
    input_stream: "IMAGE:throttled_input_video"
    input_stream: "LANDMARKS:multi_smoothed_face_landmarks"
    input_stream: "NORM_RECTS:face_rects_from_landmarks"
    input_stream: "DETECTIONS:face_detections"
    output_stream: "IMAGE:output_video"
}

# Computes face geometry from face landmarks for a single face.
node {
    calculator: "FaceGeometryFromLandmarks"
    input_stream: "MULTI_FACE_LANDMARKS:multi_smoothed_face_landmarks"
    input_stream: "IMAGE_SIZE:input_image_size"
    input_side_packet: "ENVIRONMENT:environment"
    output_stream: "MULTI_FACE_GEOMETRY:multi_face_geometry"
}
